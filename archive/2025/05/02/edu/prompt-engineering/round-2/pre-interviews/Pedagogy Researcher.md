# Interview Transcript: Pedagogy Researcher

**Date:** 2025-05-02
**Persona:** Pedagogy Researcher (PR)
**Interviewer:** Facilitator

**Facilitator:** Thanks for joining, PR. Your expertise in learning science is invaluable. From a research perspective, what are the key challenges in effectively teaching a rapidly evolving, complex skill like prompt engineering to a large group of engineers?

**PR:** Several challenges: 1) **Transfer:** Ensuring skills learned in the course transfer to diverse, real-world SE tasks. This requires authentic practice and assessment (as Prof Ed noted). 2) **Cognitive Load:** Managing the load, especially with abstract concepts (AIR) and complex workflows (AOA). Requires careful sequencing, chunking, and use of cognitive aids like visualizations (Ed UX). 3) **Metacognition:** Moving learners beyond executing techniques to reflecting on and strategically planning their prompt use (SRL, as Prof Ed mentioned). 4) **Scalability:** Designing effective instruction and, critically, *assessment* that scales to 200 learners while maintaining quality and authenticity.

**Facilitator:** Which modules are most demanding from a learning science perspective?

**PR:** Unit 3, where learners synthesize individual techniques into workflows. This requires moving up Bloom's Taxonomy towards Analysis and Application in complex scenarios. Unit 4 introduces abstract concepts (agents, meta-prompting) requiring strong conceptual change strategies. Unit 5 (Capstone) is crucial for assessing transfer and higher-order thinking (Creation/Evaluation), but challenging to design well.

**Facilitator:** What insights from learning science research feel particularly relevant here?

**PR:** Cognitive Load Theory (managing intrinsic, extraneous, germane load). Constructivism (learners actively build understanding through practice). Situated Learning Theory (learning best occurs in authentic contexts – hence the Cursor focus). Research on effective feedback (timely, specific, actionable). And principles of effective multimedia learning for visualizations.

**Facilitator:** Any blindspots engineers might have as *learners* in this domain?

**PR:** Epistemological beliefs – viewing prompting as finding the one "right" answer versus an iterative process of refinement. Difficulty transferring knowledge from familiar programming paradigms to the probabilistic nature of LLMs. Overconfidence after mastering basic techniques, leading to struggles with complex or nuanced tasks.

**Facilitator:** How do your potential contributions align with these challenges?

**PR:** Strength: Grounding the curriculum design in evidence-based learning principles. Providing research insights on effective instructional strategies (e.g., worked examples, interleaving practice) and assessment techniques (e.g., performance-based assessment, rubrics). Weakness: Translating theoretical research into practical, scalable course elements requires close collaboration with Prof Ed, Ed UX, and the technical SMEs.

**Facilitator:** Where can you best contribute during curriculum research?

**PR:** Advising on the overall pedagogical framework (with Prof Ed), ensuring alignment with learning science principles, researching effective methods for teaching specific concepts (e.g., analogies for tokenization, scaffolding for agents), contributing to the assessment strategy (R4), particularly for measuring higher-order skills and transfer.

**Facilitator:** And during development?

**PR:** Reviewing lesson plans and activities for pedagogical effectiveness, advising on the design of feedback mechanisms, potentially helping design instruments to evaluate learning outcomes or course effectiveness.

**Facilitator:** Other SMEs needed for roadmapping?

**PR:** Prof Ed is the primary collaborator. Ed UX helps translate principles into tangible learning experiences. Technical SMEs (PE, SSE, AOA) provide the domain context to ground the pedagogical strategies.

**Facilitator:** Anything else crucial?

**PR:** Evaluation. We need a plan not just to assess learners, but to evaluate the *course itself*. What data will we collect (learning outcomes, engagement, self-efficacy, application on the job) to iterate and improve the course over time? This continuous improvement loop is vital for a rapidly changing field.

**Facilitator:** A critical long-term view. Thank you, PR. 