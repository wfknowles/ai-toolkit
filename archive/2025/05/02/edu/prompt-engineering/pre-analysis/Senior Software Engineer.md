# Senior Software Engineer - Initial Outline Thoughts

**Date:** 2025-05-02
**Persona:** Senior Software Engineer (SSE)

**Review of Previous Session:** The focus on practical SE tasks within Cursor is spot on. Concepts like context engineering, debugging AI code, and evaluating outputs are critical for engineers like me to trust and use this effectively. The MVP focusing on immediate wins makes sense.

**Outline Structure Proposal (Focus on Practical SE Tasks & Skills):**

*   **Part 1: Getting Productive with AI Assistance**
    *   Module 1: Quick Start: Cursor for Common Tasks (Code Gen, Explain, Docs)
    *   Module 2: Prompting Basics for Code (Clear instructions, providing context via @/selection)
    *   Module 3: Refining AI Suggestions (Iterating on prompts, giving feedback)
    *   Module 4: Debugging with AI Help (Using chat/CoT to analyze errors, explain logic)
    *   *Goal:* Comfortable using Cursor for basic assistance, improving prompt clarity.
*   **Part 2: Advanced Code Manipulation & Context**
    *   Module 5: Effective Context for Complex Code (Strategies for large files/projects)
    *   Module 6: AI-Assisted Refactoring (Prompting for specific refactors, evaluating suggestions)
    *   Module 7: Generating Quality Tests & Boilerplate (Advanced code gen prompts)
    *   Module 8: Understanding & Controlling Output (Formatting, constraints, style guides)
    *   *Goal:* Confidently use AI for more complex code manipulation and understand context limitations.
*   **Part 3: Workflows, Evaluation & Security**
    *   Module 9: Building Simple Workflows (Prompt chaining for multi-step tasks like feature dev -> tests -> docs)
    *   Module 10: Critically Evaluating AI Code (Quality, performance, security pitfalls)
    *   Module 11: Introduction to Agentic Concepts (How planning/tool use *could* automate more)
    *   Module 12: Sharing & Reusing Effective Prompts (Team best practices)
    *   *Goal:* Integrate AI assistance into workflows, evaluate outputs critically, understand future potential.
*   **Capstone:** Apply techniques to refactor/document/test a realistic code module.

**Concerns/Feedback:** Examples *must* use relevant languages/frameworks from our stack. Need clear guidance on *when* AI helps most vs. when manual coding is faster/better. Security implications (Concept #10) need to be emphasized throughout, not just one module. How do we handle different skill levels within the 200 engineers? 